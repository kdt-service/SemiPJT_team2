{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Series.rename() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m job_keywords_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mcsv/job_keywords.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m most_similar_keywords \u001b[39m=\u001b[39m cosin_similarity(user_keywords, job_keywords_df)\n\u001b[1;32m---> 49\u001b[0m most_similar_keywords \u001b[39m=\u001b[39m most_similar_keywords\u001b[39m.\u001b[39;49mrename(columns\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mjob\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m직업\u001b[39;49m\u001b[39m\"\u001b[39;49m})  \u001b[39m# job 컬럼명을 직업으로 변경\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m가장 유사한 직무와 키워드:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[39mprint\u001b[39m(most_similar_keywords\u001b[39m.\u001b[39mdrop(labels\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m자소서갯수\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mTypeError\u001b[0m: Series.rename() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Mecab을 이용해 일반명사 추출\n",
    "def extract_nouns(text):\n",
    "    mecab = Mecab()\n",
    "    tagged = mecab.pos(text)\n",
    "    return ' '.join([word for word, pos in tagged if pos == 'NNG'])\n",
    "\n",
    "# tf-idf을 계산하여 상위 20개의 키워드 추출\n",
    "def extract_keywords(text):\n",
    "    nouns = extract_nouns(text) # 텍스트 명사 추출\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([nouns])    # 명사 기반 TF-IDF 행렬 생성\n",
    "    feature_names = vectorizer.get_feature_names_out()  # 행렬에서 키워드 목록 가져오기\n",
    "    tfidf_scores = tfidf_matrix.toarray().flatten().tolist()    # 행렬 1차원 리스트로 변환\n",
    "    top_indices = sorted(range(len(tfidf_scores)), key=lambda i: tfidf_scores[i], reverse=True)[:20]    # 상위 20개 키워드 인덱스 구하기\n",
    "    top_keywords = [feature_names[i] for i in top_indices]  # for 문 돌면서 키워드 추출\n",
    "    return top_keywords\n",
    "\n",
    "# input 자기소개서와 job_keywords.csv파일의 키워드 추출을 내용을 유사도 검사\n",
    "def cosin_similarity(user_keywords, job_keywords_df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    job_keywords_matrix = vectorizer.fit_transform(job_keywords_df['keywords'])     # 직무 키워드 기반 TF-IDF 행렬 생성\n",
    "    \n",
    "    user_keywords_str = ', '.join(user_keywords)    # input데이터 키워드 콤마구분\n",
    "    user_keywords_matrix = vectorizer.transform([user_keywords_str])    # input데이터 키워드 기반 TF-IDF 행렬 생성\n",
    "    \n",
    "    similarity_scores = cosine_similarity(user_keywords_matrix, job_keywords_matrix)    # 행렬간 코사인 유사도 계산\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "def top_similar_jobs(similarity_scores, job_keywords_df):\n",
    "    job_keywords_df = job_keywords_df.rename(columns={'job':'직무'})\n",
    "    top_indices = np.argsort(-similarity_scores.flatten())[:3]  # 유사도 점수를 내림차순으로 정렬한 인덱스 배열을 얻고 상위 3개 인덱스 선택\n",
    "    top_similar_jobs = job_keywords_df.iloc[top_indices].drop(labels=['keywords', '자소서갯수'], axis=1)  # 상위 인덱스에 해당하는 행을 가져오고 불필요한 열 삭제\n",
    "    top_similar_jobs.reset_index(drop=True, inplace=True)  # 인덱스를 재설정하고 원래 인덱스 삭제\n",
    "    top_similar_jobs.index += 1  # 인덱스를 1부터 시작하도록 이동\n",
    "    return top_similar_jobs  # 수정된 데이터프레임 반환\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"자기소개서 내용을 입력하세요: \")\n",
    "    user_keywords = extract_keywords(user_input)\n",
    "    \n",
    "    job_keywords_df = pd.read_csv('csv/job_keywords.csv')\n",
    "    similarity_scores = cosin_similarity(user_keywords, job_keywords_df)\n",
    "    top_jobs = top_similar_jobs(similarity_scores, job_keywords_df)\n",
    "\n",
    "    print(top_jobs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 유사한 기업와 키워드:\n",
      "company                 중소기업은행\n",
      "keywords    은행, 금융, 고객, 기업, 생각\n",
      "Name: 439, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Mecab을 이용해 일반명사 추출\n",
    "def extract_nouns(text):\n",
    "    mecab = Mecab()\n",
    "    tagged = mecab.pos(text)\n",
    "    return ' '.join([word for word, pos in tagged if pos == 'NNG'])\n",
    "\n",
    "# tf-idf을 계산하여 상위 20개의 키워드 추출\n",
    "def extract_keywords(text):\n",
    "    nouns = extract_nouns(text) # 텍스트 명사 추출\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([nouns])    # 명사 기반 TF-IDF 행렬 생성\n",
    "    feature_names = vectorizer.get_feature_names_out()  # 행렬에서 키워드 목록 가져오기\n",
    "    tfidf_scores = tfidf_matrix.toarray().flatten().tolist()    # 행렬 1차원 리스트로 변환\n",
    "    top_indices = sorted(range(len(tfidf_scores)), key=lambda i: tfidf_scores[i], reverse=True)[:20]    # 상위 20개 키워드 인덱스 구하기\n",
    "    top_keywords = [feature_names[i] for i in top_indices]  # for 문 돌면서 키워드 추출\n",
    "    return top_keywords\n",
    "\n",
    "# input 자기소개서와 company_keywords.csv파일의 키워드 추출을 내용을 유사도 검사\n",
    "def cosin_similarity(user_keywords, company_keywords_df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    company_keywords_matrix = vectorizer.fit_transform(company_keywords_df['keywords'])     # 직무 키워드 기반 TF-IDF 행렬 생성\n",
    "    \n",
    "    user_keywords_str = ', '.join(user_keywords)    # input데이터 키워드 콤마구분\n",
    "    user_keywords_matrix = vectorizer.transform([user_keywords_str])    # input데이터 키워드 기반 TF-IDF 행렬 생성\n",
    "    \n",
    "    similarity_scores = cosine_similarity(user_keywords_matrix, company_keywords_matrix)    # 행렬간 코사인 유사도 계산\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "def top_similar_companys(similarity_scores, job_keywords_df):\n",
    "    job_keywords_df = job_keywords_df.rename(columns={'company':'기업'})\n",
    "    top_indices = np.argsort(-similarity_scores.flatten())[:3]  # 유사도 점수를 내림차순으로 정렬한 인덱스 배열을 얻고 상위 3개 인덱스 선택\n",
    "    top_similar_companys = job_keywords_df.iloc[top_indices].drop(labels=['keywords', '자소서갯수'], axis=1)  # 상위 인덱스에 해당하는 행을 가져오고 불필요한 열 삭제\n",
    "    top_similar_companys.reset_index(drop=True, inplace=True)  # 인덱스를 재설정하고 원래 인덱스 삭제\n",
    "    top_similar_companys.index += 1  # 인덱스를 1부터 시작하도록 이동\n",
    "    return top_similar_companys  # 수정된 데이터프레임 반환\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"자기소개서 내용을 입력하세요: \")\n",
    "    user_keywords = extract_keywords(user_input)\n",
    "    \n",
    "    company_keywords_df = pd.read_csv('csv/company_keywords.csv')\n",
    "    similarity_scores = cosin_similarity(user_keywords, company_keywords_df)\n",
    "    top_companys = top_similar_companys(similarity_scores, company_keywords_df)\n",
    "\n",
    "    print(top_companys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
