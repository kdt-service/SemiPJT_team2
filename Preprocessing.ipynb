{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./jobkorea.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>work_type</th>\n",
       "      <th>job</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>오스템임플란트에 입사 지원한 동기/이유를 설명해 주세요.</td>\n",
       "      <td>\"현실이 주는 안락함에 도취하지 않고 도약을 멈추지 않는 오스템임플란트\" 임플란트 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>과거 경험 中 본인의 실패 사례를 소개해 주세요.</td>\n",
       "      <td>\"감성과 이성을 아울러 성공을 향해 함께 나아가다.\" OOOOO 차장으로서 OOOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>본인의 열정 발휘 사례를 소개해 주세요.</td>\n",
       "      <td>\"소통이 중심이 된 기획력과 문제해결력으로 비효율성을 해결하다.\" 대대 인사행정병으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>입사 후 지원 분야에 본인이 기여할 수 있는 방안에 대해 설명해 주세요.</td>\n",
       "      <td>\"다채로운 관련 경험으로 습득한 학술행사 노하우\" 학교, 군대, 지자체를 아우르며 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>입사 지원 분야에 대한 본인의 직무 수행 경험을 설명해 주세요.</td>\n",
       "      <td>\"경험을 바탕으로 성장하는 제너럴리스트\" 주도적으로 다양한 분야에서 행사 기획과 운...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29484</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등과 같이 낯선 단...</td>\n",
       "      <td>[꾸준한 반복의 힘] G1 강원민방에서 단종뎐, 민심에 살아있는 임금이라는 프로그램...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29485</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력하는 사람임을...</td>\n",
       "      <td>[팀원을 하나로 만드는 원칙] 대학생 봉사단의 영상팀장으로 활동하며 CSR 필름 페...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29486</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>[의사소통능력] 자신이 속했던 조직(학교, 회사, 동아리 등) 안에서 자신과 의견이...</td>\n",
       "      <td>복지관에서 실습을 할 때, 어르신이 가진 편견을 깨고 수입조사를 무사히 끝낸 경험이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29487</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>[조직이해능력] 봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등...</td>\n",
       "      <td>노인복지관에서 봉사활동을 할 때, 프로그램 접수업무를 맡아서 진행한 적이 있습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29488</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>[직업윤리] 자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력...</td>\n",
       "      <td>직접 후원금을 모금하여 복지관 행사를 성공적으로 추진했던 경험이 있습니다. 여러 사...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29489 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      section     company       date work_type        job  \\\n",
       "0       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "1       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "2       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "3       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "4       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "...       ...         ...        ...       ...        ...   \n",
       "29484   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29485   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29486   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29487   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29488   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "\n",
       "                                                question  \\\n",
       "0                        오스템임플란트에 입사 지원한 동기/이유를 설명해 주세요.   \n",
       "1                            과거 경험 中 본인의 실패 사례를 소개해 주세요.   \n",
       "2                                 본인의 열정 발휘 사례를 소개해 주세요.   \n",
       "3               입사 후 지원 분야에 본인이 기여할 수 있는 방안에 대해 설명해 주세요.   \n",
       "4                    입사 지원 분야에 대한 본인의 직무 수행 경험을 설명해 주세요.   \n",
       "...                                                  ...   \n",
       "29484  봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등과 같이 낯선 단...   \n",
       "29485  자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력하는 사람임을...   \n",
       "29486  [의사소통능력] 자신이 속했던 조직(학교, 회사, 동아리 등) 안에서 자신과 의견이...   \n",
       "29487  [조직이해능력] 봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등...   \n",
       "29488  [직업윤리] 자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력...   \n",
       "\n",
       "                                                  answer  \n",
       "0      \"현실이 주는 안락함에 도취하지 않고 도약을 멈추지 않는 오스템임플란트\" 임플란트 ...  \n",
       "1      \"감성과 이성을 아울러 성공을 향해 함께 나아가다.\" OOOOO 차장으로서 OOOO...  \n",
       "2      \"소통이 중심이 된 기획력과 문제해결력으로 비효율성을 해결하다.\" 대대 인사행정병으...  \n",
       "3      \"다채로운 관련 경험으로 습득한 학술행사 노하우\" 학교, 군대, 지자체를 아우르며 ...  \n",
       "4      \"경험을 바탕으로 성장하는 제너럴리스트\" 주도적으로 다양한 분야에서 행사 기획과 운...  \n",
       "...                                                  ...  \n",
       "29484  [꾸준한 반복의 힘] G1 강원민방에서 단종뎐, 민심에 살아있는 임금이라는 프로그램...  \n",
       "29485  [팀원을 하나로 만드는 원칙] 대학생 봉사단의 영상팀장으로 활동하며 CSR 필름 페...  \n",
       "29486  복지관에서 실습을 할 때, 어르신이 가진 편견을 깨고 수입조사를 무사히 끝낸 경험이...  \n",
       "29487  노인복지관에서 봉사활동을 할 때, 프로그램 접수업무를 맡아서 진행한 적이 있습니다....  \n",
       "29488  직접 후원금을 모금하여 복지관 행사를 성공적으로 추진했던 경험이 있습니다. 여러 사...  \n",
       "\n",
       "[29489 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='answer', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>work_type</th>\n",
       "      <th>job</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>오스템임플란트에 입사 지원한 동기/이유를 설명해 주세요.</td>\n",
       "      <td>\"현실이 주는 안락함에 도취하지 않고 도약을 멈추지 않는 오스템임플란트\" 임플란트 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>과거 경험 中 본인의 실패 사례를 소개해 주세요.</td>\n",
       "      <td>\"감성과 이성을 아울러 성공을 향해 함께 나아가다.\" OOOOO 차장으로서 OOOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>본인의 열정 발휘 사례를 소개해 주세요.</td>\n",
       "      <td>\"소통이 중심이 된 기획력과 문제해결력으로 비효율성을 해결하다.\" 대대 인사행정병으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>입사 후 지원 분야에 본인이 기여할 수 있는 방안에 대해 설명해 주세요.</td>\n",
       "      <td>\"다채로운 관련 경험으로 습득한 학술행사 노하우\" 학교, 군대, 지자체를 아우르며 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기획·전략</td>\n",
       "      <td>오스템임플란트(주)</td>\n",
       "      <td>2022년 하반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>경영·비즈니스기획</td>\n",
       "      <td>입사 지원 분야에 대한 본인의 직무 수행 경험을 설명해 주세요.</td>\n",
       "      <td>\"경험을 바탕으로 성장하는 제너럴리스트\" 주도적으로 다양한 분야에서 행사 기획과 운...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29484</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등과 같이 낯선 단...</td>\n",
       "      <td>[꾸준한 반복의 힘] G1 강원민방에서 단종뎐, 민심에 살아있는 임금이라는 프로그램...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29485</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력하는 사람임을...</td>\n",
       "      <td>[팀원을 하나로 만드는 원칙] 대학생 봉사단의 영상팀장으로 활동하며 CSR 필름 페...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29486</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>[의사소통능력] 자신이 속했던 조직(학교, 회사, 동아리 등) 안에서 자신과 의견이...</td>\n",
       "      <td>복지관에서 실습을 할 때, 어르신이 가진 편견을 깨고 수입조사를 무사히 끝낸 경험이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29487</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>[조직이해능력] 봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등...</td>\n",
       "      <td>노인복지관에서 봉사활동을 할 때, 프로그램 접수업무를 맡아서 진행한 적이 있습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29488</th>\n",
       "      <td>공공·복지</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>2016년 상반기</td>\n",
       "      <td>신입</td>\n",
       "      <td>사회복지사</td>\n",
       "      <td>[직업윤리] 자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력...</td>\n",
       "      <td>직접 후원금을 모금하여 복지관 행사를 성공적으로 추진했던 경험이 있습니다. 여러 사...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29121 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      section     company       date work_type        job  \\\n",
       "0       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "1       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "2       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "3       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "4       기획·전략  오스템임플란트(주)  2022년 하반기        신입  경영·비즈니스기획   \n",
       "...       ...         ...        ...       ...        ...   \n",
       "29484   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29485   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29486   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29487   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "29488   공공·복지    국민건강보험공단  2016년 상반기        신입      사회복지사   \n",
       "\n",
       "                                                question  \\\n",
       "0                        오스템임플란트에 입사 지원한 동기/이유를 설명해 주세요.   \n",
       "1                            과거 경험 中 본인의 실패 사례를 소개해 주세요.   \n",
       "2                                 본인의 열정 발휘 사례를 소개해 주세요.   \n",
       "3               입사 후 지원 분야에 본인이 기여할 수 있는 방안에 대해 설명해 주세요.   \n",
       "4                    입사 지원 분야에 대한 본인의 직무 수행 경험을 설명해 주세요.   \n",
       "...                                                  ...   \n",
       "29484  봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등과 같이 낯선 단...   \n",
       "29485  자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력하는 사람임을...   \n",
       "29486  [의사소통능력] 자신이 속했던 조직(학교, 회사, 동아리 등) 안에서 자신과 의견이...   \n",
       "29487  [조직이해능력] 봉사활동이나 프로젝트 모임, 동아리, 현장 실습이나 인턴 기업체 등...   \n",
       "29488  [직업윤리] 자신이 속한 팀이나 집단 전체의 이익을 위하여 주도적으로 행동하고 노력...   \n",
       "\n",
       "                                                  answer  \n",
       "0      \"현실이 주는 안락함에 도취하지 않고 도약을 멈추지 않는 오스템임플란트\" 임플란트 ...  \n",
       "1      \"감성과 이성을 아울러 성공을 향해 함께 나아가다.\" OOOOO 차장으로서 OOOO...  \n",
       "2      \"소통이 중심이 된 기획력과 문제해결력으로 비효율성을 해결하다.\" 대대 인사행정병으...  \n",
       "3      \"다채로운 관련 경험으로 습득한 학술행사 노하우\" 학교, 군대, 지자체를 아우르며 ...  \n",
       "4      \"경험을 바탕으로 성장하는 제너럴리스트\" 주도적으로 다양한 분야에서 행사 기획과 운...  \n",
       "...                                                  ...  \n",
       "29484  [꾸준한 반복의 힘] G1 강원민방에서 단종뎐, 민심에 살아있는 임금이라는 프로그램...  \n",
       "29485  [팀원을 하나로 만드는 원칙] 대학생 봉사단의 영상팀장으로 활동하며 CSR 필름 페...  \n",
       "29486  복지관에서 실습을 할 때, 어르신이 가진 편견을 깨고 수입조사를 무사히 끝낸 경험이...  \n",
       "29487  노인복지관에서 봉사활동을 할 때, 프로그램 접수업무를 맡아서 진행한 적이 있습니다....  \n",
       "29488  직접 후원금을 모금하여 복지관 행사를 성공적으로 추진했던 경험이 있습니다. 여러 사...  \n",
       "\n",
       "[29121 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('생각', 34302), ('경험', 25865), ('업무', 23932), ('고객', 22745), ('사람', 17071), ('노력', 16389), ('진행', 13075), ('결과', 13051), ('목표', 12929), ('후', 12574)]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.json\"\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "\n",
    "korean_stopwords = data\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "\n",
    "mecab = Mecab(dicpath=r\"C:/mecab/mecab-ko-dic\")\n",
    "\n",
    "text_list = df['answer'].tolist()\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for text in text_list:\n",
    "    sentences = nltk.sent_tokenize(text)  # 한국어 문장 토큰화 지원이 제한적이므로 영어 설정\n",
    "    for sent in sentences:\n",
    "        words = mecab.pos(sent)\n",
    "        filtered_words = [word[0] for word in words if word[1] in ['NNG', 'NNP'] and word[0] not in korean_stopwords]\n",
    "        tokens.extend(filtered_words)\n",
    "\n",
    "freq_dist = FreqDist(tokens)\n",
    "print(freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "# 한국어 불용어 불러오기\n",
    "# 공백문자 제거하고 set으로 저장함(중복제거)\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "# 텍스트를 입력받아 불용어 처리 후 Mecab을 사용하여 품사 태깅을 수행하는 함수\n",
    "def mecab_tokenize(text, stopwords):\n",
    "    Tag = []\n",
    "    mecab = Mecab(dicpath=r\"C:/mecab/mecab-ko-dic\")\n",
    "    tokens = mecab.morphs(text)\n",
    "    # 불용어가 아닌 단어들을 태깅\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    for token in filtered_tokens:\n",
    "        Tag += mecab.pos(token)\n",
    "    return Tag  # 태깅된 토큰들\n",
    "\n",
    "# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\n",
    "df['pos'] = df['answer'].apply(lambda x: mecab_tokenize(x, korean_stopwords))\n",
    "df.to_csv('jobkorea_pos_mecab.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m Tag  \u001b[39m# 태깅된 토큰들\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39manswer\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: okt_tokenize(x, stopwords))\n\u001b[0;32m     22\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mjobkorea_pos_okt.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m Tag  \u001b[39m# 태깅된 토큰들\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: okt_tokenize(x, stopwords))\n\u001b[0;32m     22\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mjobkorea_pos_okt.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[37], line 17\u001b[0m, in \u001b[0;36mokt_tokenize\u001b[1;34m(text, stopwords)\u001b[0m\n\u001b[0;32m     15\u001b[0m filtered_tokens \u001b[39m=\u001b[39m [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m token \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords]\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m filtered_tokens:\n\u001b[1;32m---> 17\u001b[0m     Tag \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m okt\u001b[39m.\u001b[39;49mpos(token)\n\u001b[0;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m Tag\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\konlpy\\tag\\_okt.py:71\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mIn contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mthis POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m:param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m validate_phrase_inputs(phrase)\n\u001b[1;32m---> 71\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjki\u001b[39m.\u001b[39;49mtokenize(\n\u001b[0;32m     72\u001b[0m             phrase,\n\u001b[0;32m     73\u001b[0m             jpype\u001b[39m.\u001b[39;49mjava\u001b[39m.\u001b[39;49mlang\u001b[39m.\u001b[39;49mBoolean(norm),\n\u001b[0;32m     74\u001b[0m             jpype\u001b[39m.\u001b[39;49mjava\u001b[39m.\u001b[39;49mlang\u001b[39m.\u001b[39;49mBoolean(stem))\u001b[39m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m join:\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokens]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "# 한국어 불용어 불러오기\n",
    "# 공백문자 제거하고 set으로 저장함(중복제거)\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "# 텍스트를 입력받아 불용어 처리 후 Okt를 사용하여 품사 태깅을 수행하는 함수\n",
    "def okt_tokenize(text, stopwords):\n",
    "    Tag = []\n",
    "    okt = Okt()\n",
    "    tokens = okt.morphs(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    for token in filtered_tokens:\n",
    "        Tag += okt.pos(token)\n",
    "    return Tag  # 태깅된 토큰들\n",
    "\n",
    "# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\n",
    "df['pos'] = df['answer'].apply(lambda x: okt_tokenize(x, stopwords))\n",
    "df.to_csv('jobkorea_pos_okt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "# 한국어 불용어 불러오기\n",
    "# 공백문자 제거하고 set으로 저장함(중복제거)\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "# 텍스트를 입력받아 불용어 처리 후 Mecab을 사용하여 품사 태깅을 수행하는 함수\n",
    "def mecab_tokenize(text, stopwords):\n",
    "    mecab = Mecab(dicpath=r\"C:/mecab/mecab-ko-dic\")\n",
    "    # Mecab을 이용해서 문장에서 명사와 동사 품사만 추출한다.\n",
    "    tokens = [word for word in mecab.pos(text) if word[1][0] in ['N', 'V']]\n",
    "    # 추출한 단어중 불용어를 제외한 단어를 리스트에 반환한다.\n",
    "    tokens = [word for word, pos in tokens if word not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\n",
    "df['pos'] = df['answer'].apply(lambda x: mecab_tokenize(x, stopwords))\n",
    "df.to_csv('jobkorea_pos_mecab_nv.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "# 한국어 불용어 불러오기\n",
    "# 공백문자 제거하고 set으로 저장함(중복제거)\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "# 텍스트를 입력받아 불용어 처리 후 Mecab을 사용하여 품사 태깅을 수행하는 함수\n",
    "def mecab_tokenize(text, stopwords):\n",
    "    Tag = []\n",
    "    mecab = Mecab(dicpath=r\"C:/mecab/mecab-ko-dic\")\n",
    "    tokens = mecab.morphs(text)\n",
    "    # 불용어가 아닌 단어들을 태깅\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    tagged_tokens = mecab.pos(' '.join(filtered_tokens))\n",
    "    for token, pos in tagged_tokens:\n",
    "        # 명사와 동사만 추출\n",
    "        if pos in ['NNG', 'NNP', 'NNB', 'NR', 'VV']:\n",
    "            Tag.append((token, pos))\n",
    "    return Tag  # 태깅된 토큰들\n",
    "\n",
    "# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\n",
    "df['pos'] = df['answer'].apply(lambda x: mecab_tokenize(x, stopwords))\n",
    "df.to_csv('jobkorea_pos_mecab_NV.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m Tag  \u001b[39m# 태깅된 토큰들\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39manswer\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: okt_tokenize(x, stopwords))\n\u001b[0;32m     28\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mjobkorea_pos_okt_NV.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[41], line 27\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m Tag  \u001b[39m# 태깅된 토큰들\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: okt_tokenize(x, stopwords))\n\u001b[0;32m     28\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mjobkorea_pos_okt_NV.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 15\u001b[0m, in \u001b[0;36mokt_tokenize\u001b[1;34m(text, stopwords)\u001b[0m\n\u001b[0;32m     13\u001b[0m Tag \u001b[39m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m okt \u001b[39m=\u001b[39m Okt()\n\u001b[1;32m---> 15\u001b[0m tokens \u001b[39m=\u001b[39m okt\u001b[39m.\u001b[39;49mmorphs(text)\n\u001b[0;32m     16\u001b[0m \u001b[39m# 불용어가 아닌 단어들을 태깅\u001b[39;00m\n\u001b[0;32m     17\u001b[0m filtered_tokens \u001b[39m=\u001b[39m [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m token \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords]\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\konlpy\\tag\\_okt.py:89\u001b[0m, in \u001b[0;36mOkt.morphs\u001b[1;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmorphs\u001b[39m(\u001b[39mself\u001b[39m, phrase, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, stem\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m [s \u001b[39mfor\u001b[39;00m s, t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos(phrase, norm\u001b[39m=\u001b[39;49mnorm, stem\u001b[39m=\u001b[39;49mstem)]\n",
      "File \u001b[1;32mc:\\Users\\pil06\\anaconda3\\envs\\study\\lib\\site-packages\\konlpy\\tag\\_okt.py:71\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mIn contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mthis POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m:param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m validate_phrase_inputs(phrase)\n\u001b[1;32m---> 71\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjki\u001b[39m.\u001b[39;49mtokenize(\n\u001b[0;32m     72\u001b[0m             phrase,\n\u001b[0;32m     73\u001b[0m             jpype\u001b[39m.\u001b[39;49mjava\u001b[39m.\u001b[39;49mlang\u001b[39m.\u001b[39;49mBoolean(norm),\n\u001b[0;32m     74\u001b[0m             jpype\u001b[39m.\u001b[39;49mjava\u001b[39m.\u001b[39;49mlang\u001b[39m.\u001b[39;49mBoolean(stem))\u001b[39m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m join:\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokens]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "# 한국어 불용어 불러오기\n",
    "# 공백문자 제거하고 set으로 저장함(중복제거)\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "# 텍스트를 입력받아 불용어 처리 후 Okt를 사용하여 품사 태깅을 수행하는 함수\n",
    "def okt_tokenize(text, stopwords):\n",
    "    Tag = []\n",
    "    okt = Okt()\n",
    "    tokens = okt.morphs(text)\n",
    "    # 불용어가 아닌 단어들을 태깅\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    tagged_tokens = okt.pos(' '.join(filtered_tokens))\n",
    "    for token, pos in tagged_tokens:\n",
    "        # 명사와 동사만 추출\n",
    "        if pos.startswith('Noun') or pos.startswith('Verb'):\n",
    "            Tag.append((token, pos))\n",
    "    return Tag  # 태깅된 토큰들\n",
    "\n",
    "# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\n",
    "df['pos'] = df['answer'].apply(lambda x: okt_tokenize(x, stopwords))\n",
    "df.to_csv('jobkorea_pos_okt_NV.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import concurrent.futures\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "def mecab_tokenize(text):\n",
    "    Tag = []\n",
    "    mecab = Mecab(dicpath=r\"C:/mecab/mecab-ko-dic\")\n",
    "    tokens = mecab.morphs(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    tagged_tokens = mecab.pos(' '.join(filtered_tokens))\n",
    "    for token, pos in tagged_tokens:\n",
    "        if pos in ['NNG', 'NNP', 'NNB', 'NR', 'VV']:\n",
    "            Tag.append((token, pos))\n",
    "    return Tag\n",
    "\n",
    "def tokenize_and_update_df(index, text):\n",
    "    df.at[index, 'pos'] = str(okt_tokenize(text))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(tokenize_and_update_df, df.index, df['answer'])\n",
    "\n",
    "df.to_csv('jobkorea_pos_mecab_NV.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "import concurrent.futures\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "def okt_tokenize(text):\n",
    "    Tag = []\n",
    "    okt = Okt()\n",
    "    tokens = okt.morphs(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    tagged_tokens = okt.pos(' '.join(filtered_tokens))\n",
    "    for token, pos in tagged_tokens:\n",
    "        if pos in ['Noun', 'Verb']:\n",
    "            Tag.append((token, pos))\n",
    "    return Tag\n",
    "\n",
    "def tokenize_and_update_df(index, text):\n",
    "    df.at[index, 'pos'] = okt_tokenize(text)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(tokenize_and_update_df, df.index, df['answer'])\n",
    "\n",
    "df.to_csv('jobkorea_pos_okt_NV.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "df = pd.read_csv('./jobkorea.csv')\n",
    "\n",
    "# 한국어 불용어 불러오기\n",
    "# 공백문자 제거하고 set으로 저장함(중복제거)\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "# 텍스트를 입력받아 불용어 처리 후 Mecab을 사용하여 품사 태깅을 수행하는 함수\n",
    "def mecab_tokenize(text, stopwords):\n",
    "    Tag = []\n",
    "    mecab = Mecab(dicpath=r\"C:/mecab/mecab-ko-dic\")\n",
    "    tokens = mecab.morphs(text)\n",
    "    # 불용어가 아닌 단어들을 태깅\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    for token in filtered_tokens:\n",
    "        tagged_token = mecab.pos(token)\n",
    "        # 'NNG', 'NNP', 'NNB', 'NR', 'VV' 태그를 가진 토큰만 추가\n",
    "        Tag += [t for t in tagged_token if t[1] in ('NNG', 'NNP', 'NNB', 'NR', 'VV')]\n",
    "    return Tag  # 태깅된 토큰들\n",
    "\n",
    "# 데이터프레임에 불용어 처리된 품사 태깅 결과를 저장\n",
    "df['pos'] = df['answer'].apply(lambda x: mecab_tokenize(x, stopwords))\n",
    "df.to_csv('jobkorea_pos_mecab_NVV.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
