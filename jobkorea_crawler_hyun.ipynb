{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_dict = {\n",
    "    '기획·전략' : '10026',\n",
    "    '법무·사무·총무' : '10027',\n",
    "    '인사·HR' : '10028',\n",
    "    '회계·세무' : '10029',\n",
    "    '마케팅·광고·MD' : '10030',\n",
    "    '개발·데이터' : '10031',\n",
    "    '디자인' : '10032',\n",
    "    '물류·무역' : '10033',\n",
    "    '운전·운송·배송' : '10034',\n",
    "    '영업' : '10035',\n",
    "    '고객상담·TM' : '10036',\n",
    "    '금융·보험' : '10037',\n",
    "    '식·음료' : '10038',\n",
    "    '고객서비스·리테일' : '10039',\n",
    "    '엔지니어링·설계' : '10040',\n",
    "    '제조·생산' : '10041',\n",
    "    '교육' : '10042',\n",
    "    '건축·시설' : '10043',\n",
    "    '의료·바이오' : '10044',\n",
    "    '미디어·문화·스포츠' : '10045',\n",
    "    '공공·복지' : '10046'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"section\", \"company\", \"date\", \"work_type\", \"job\", \"apply_info\", \"question\", \"answer\"])\n",
    "df.to_csv(\"./data/coverletter_df.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c2b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for section_name, section_id in section_dict.items():\n",
    "    \n",
    "    page = 1\n",
    "    BASE_URL = \"https://www.jobkorea.co.kr/starter/PassAssay\" + f\"?schPart={section_id}\"\n",
    "    \n",
    "    print(section_name + \" 시작!\")\n",
    "\n",
    "    while True:\n",
    "        URL = BASE_URL + f\"&Page={page}\"\n",
    "        response = requests.get(URL)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        if soup.find(class_=\"scNoSelect\"):\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            essay_list = soup.find(class_=\"selfLists\").find_all(class_=\"txBx\")\n",
    "\n",
    "            for essay in essay_list:\n",
    "\n",
    "                # Job Info\n",
    "                url = \"https://www.jobkorea.co.kr/\" + essay.find(\"a\")[\"href\"]\n",
    "                company = essay.find(class_=\"titTx\").text\n",
    "                season = essay.find(class_=\"career\").text\n",
    "                work_type = essay.find_all(class_=\"field\")[0].text\n",
    "                job = essay.find_all(class_=\"field\")[1].text\n",
    "\n",
    "                # Essay Info\n",
    "\n",
    "                try:\n",
    "                    response = requests.get(url)\n",
    "                    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                    apply_info = soup.find(class_=\"specLists\").text.strip().split('\\n')[:-1]\n",
    "\n",
    "                    qna_list = soup.find(class_=\"qnaLists\")\n",
    "\n",
    "                    q_list = []\n",
    "                    for q in qna_list.find_all(\"dt\"):\n",
    "                        q_text = q.find(class_=\"tx\").text\n",
    "                        q_list.append(q_text)\n",
    "\n",
    "                    a_list = []\n",
    "                    for a in qna_list.find_all(\"dd\"):\n",
    "                        a_text = a.find(class_=\"tx\").text\n",
    "                        a_text = a_text[:-20].replace(\"\\r\", \"\").replace(\"답변\", \"\").strip()\n",
    "                        a_list.append(a_text)\n",
    "\n",
    "                    qna_text = list(zip(q_list, a_list))\n",
    "\n",
    "                    # Save data\n",
    "                    insert_data = []\n",
    "                    for text in qna_text:\n",
    "                        data = []\n",
    "                        data.append(section_name)\n",
    "                        data.append(company)\n",
    "                        data.append(season)\n",
    "                        data.append(work_type)\n",
    "                        data.append(job)\n",
    "                        data.append(apply_info)\n",
    "                        data.append(text[0])\n",
    "                        data.append(text[1])\n",
    "                        insert_data.append(data)\n",
    "\n",
    "                    insert_df = pd.DataFrame(data=insert_data)\n",
    "                    insert_df.to_csv(\"./data/coverletter_df.csv\", mode=\"a\", header=False, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "        print(str(page) + \" 페이지 완료!\")\n",
    "        page += 1\n",
    "    \n",
    "    print(section_name + \" 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
